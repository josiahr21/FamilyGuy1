{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40f67921-6279-4722-8c6c-42f94d38bf4e",
   "metadata": {},
   "source": [
    "Transcript Files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0748d7ed-a5fc-44f1-8442-cd7363f1411c",
   "metadata": {},
   "source": [
    "The coding below is made to list a specific emotion in what's said in these transcripts throughout Season 21 and 22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08d02d4a-f78e-46ab-b92e-906ff3c15fa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-md==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.7.1/en_core_web_md-3.7.1-py3-none-any.whl (42.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /Users/liz/lib/python3.11/site-packages (from en-core-web-md==3.7.1) (3.7.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/liz/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/liz/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/liz/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/liz/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/liz/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /Users/liz/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (8.2.3)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/liz/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/liz/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/liz/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /Users/liz/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /Users/liz/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.9.4)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Users/liz/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (6.4.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/liz/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (4.66.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/liz/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Users/liz/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.6.4)\n",
      "Requirement already satisfied: jinja2 in /Users/liz/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.1.3)\n",
      "Requirement already satisfied: setuptools in /Users/liz/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (65.5.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/liz/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (24.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/liz/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /Users/liz/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (1.26.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/liz/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /Users/liz/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.16.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/liz/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/liz/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/liz/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/liz/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/liz/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2024.2.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/liz/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/liz/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.1.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/liz/lib/python3.11/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /Users/liz/lib/python3.11/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/liz/lib/python3.11/site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-md==3.7.1) (2.1.5)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_md')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n",
      "current working directory: /Users/liz/Documents/FamilyGuy/Jupyter\n",
      "inside this directory are the following files AND directories: ['similarityReadings.txt', '.ipynb_checkpoints']\n",
      "/Users/liz/Documents/FamilyGuy/Jupyter/TXT_files\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/liz/Documents/FamilyGuy/Jupyter/TXT_files'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 69\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;66;03m# ebb: This controls our file handling as a for loop over the directory:\u001b[39;00m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msimilarityReadings.txt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf8\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m---> 69\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCollPath\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[1;32m     70\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m file\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     71\u001b[0m             filepath \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCollPath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/liz/Documents/FamilyGuy/Jupyter/TXT_files'"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import os, shutil\n",
    "from dicttoxml import dicttoxml\n",
    "from xml.dom.minidom import parseString\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# nlp = spacy.cli.download(\"en_core_web_md\")\n",
    "# nlp = spacy.load('en_core_web_md')\n",
    "\n",
    "workingDir = os.getcwd()\n",
    "print(\"current working directory: \" + workingDir)\n",
    "\n",
    "insideDir = os.listdir(workingDir)\n",
    "print(\"inside this directory are the following files AND directories: \" + str(insideDir))\n",
    "\n",
    "CollPath = os.path.join(workingDir, 'TXT_files')\n",
    "print(CollPath)\n",
    "\n",
    "\n",
    "def readTextFiles(filepath):\n",
    "    with open(filepath, 'r', encoding='utf8') as f:\n",
    "        readFile = f.read()\n",
    "       \n",
    "        stringFile = str(readFile)\n",
    "        lengthFile = len(readFile)\n",
    "        print(lengthFile)\n",
    "       \n",
    "        tokens = nlp(stringFile)\n",
    "        \n",
    "        vectors = tokens.vector\n",
    "\n",
    "        wordOfInterest = nlp(u'joking')\n",
    "       \n",
    "        highSimilarityDict = {}\n",
    "        for token in tokens:\n",
    "            if (token and token.vector_norm):\n",
    "                if wordOfInterest.similarity(token) > .3:\n",
    "                    highSimilarityDict[token] = wordOfInterest.similarity(token)\n",
    "        print(\"This is a dictionary of words most similar to the word \" + wordOfInterest.text + \" in this file.\")\n",
    "        print(highSimilarityDict)\n",
    "        switcheroo = {val: key for key, val in highSimilarityDict.items()}\n",
    "        deduped = {val: key for key, val in switcheroo.items()}\n",
    "        print(str(len(switcheroo)) + ' **** ' + f'{switcheroo=}')\n",
    "\n",
    "        print(len(deduped), ' **** ', f'{deduped=}')\n",
    "        print(len(deduped.items()), \" vs \", len(highSimilarityDict.items()))\n",
    "\n",
    "        highSimilarityReduced = {}\n",
    "        for key, value in highSimilarityDict.items():\n",
    "            if value not in highSimilarityReduced.values():\n",
    "                highSimilarityReduced[key] = value\n",
    "        print(highSimilarityReduced)\n",
    "        print(len(highSimilarityReduced.items()), \" vs \", len(highSimilarityDict.items()))\n",
    "\n",
    "\n",
    "        sortedSimValues = sorted(deduped.items(), key=lambda x: x[1], reverse=True)\n",
    "        print(type(sortedSimValues), f'{sortedSimValues=}')\n",
    "\n",
    "        sortedSimDict = dict(sortedSimValues)\n",
    "        print(type(sortedSimValues), f'{sortedSimValues=}')\n",
    "\n",
    "        return sortedSimDict\n",
    "\n",
    "\n",
    "# ebb: This controls our file handling as a for loop over the directory:\n",
    "with open('similarityReadings.txt', 'a', encoding='utf8') as f:\n",
    "    for file in sorted(os.listdir(CollPath)):\n",
    "        if file.endswith(\".txt\"):\n",
    "            filepath = f\"{CollPath}/{file}\"\n",
    "            print(filepath)\n",
    "            similarityData = readTextFiles(filepath)\n",
    "            f.write(filepath + '\\n')\n",
    "            f.write(str(similarityData) + '\\n\\n')\n",
    "    if os.path.exists(\"JSON-output\"):\n",
    "        shutil.rmtree(\"JSON-output\")\n",
    "    if os.path.exists(\"csv-output\"):\n",
    "        shutil.rmtree(\"csv-output\")\n",
    "    if os.path.exists(\"xml-output\"):\n",
    "        shutil.rmtree(\"xml-output\")\n",
    "    os.mkdir('JSON-output')\n",
    "    os.mkdir('csv-output')\n",
    "    os.mkdir('xml-output')\n",
    "\n",
    "    df = pd.DataFrame.from_dict(similarityData.items(), orient=\"columns\")\n",
    "    df.columns = ['token', 'similarity']\n",
    "    print(df)\n",
    "    df.to_csv(f'csv-output/{file}.tsv', sep='\\t', index=False, encoding='utf-8')\n",
    "\n",
    "if os.path.exists(\"JSON-output\"):\n",
    "    shutil.rmtree(\"JSON-output\")\n",
    "if os.path.exists(\"csv-output\"):\n",
    "    shutil.rmtree(\"csv-output\")\n",
    "if os.path.exists(\"xml-output\"):\n",
    "    shutil.rmtree(\"xml-output\")\n",
    "\n",
    "os.mkdir('JSON-output')\n",
    "os.mkdir('csv-output')\n",
    "os.mkdir('xml-output')\n",
    "\n",
    "for file in sorted(os.listdir(CollPath)):\n",
    "    if file.endswith(\".txt\"):\n",
    "        filepath = f\"{CollPath}/{file}\"\n",
    "        print(filepath)\n",
    "        filenameTxt = os.path.basename(filepath).split('/')[-1]\n",
    "        filename = filenameTxt[:-4]\n",
    "        print(filename)\n",
    "        similarityData = readTextFiles(filepath)\n",
    "\n",
    "        stringKeys = {str(key): val for key, val in similarityData.items()}\n",
    "        print(f'{stringKeys=}')\n",
    "        with open(f'JSON-output/{filename}.json', 'w') as fp:\n",
    "            JSON = json.dumps(stringKeys)\n",
    "            print(f'{JSON=}')\n",
    "            json.dump(stringKeys, fp)\n",
    "        stringKeys = {str(key): val for key, val in similarityData.items()}\n",
    "        print(f'{stringKeys=}')\n",
    "        with open(f'JSON-output/{filename}.json', 'w') as fp:\n",
    "            JSON = json.dumps(stringKeys)\n",
    "            print(f'{JSON=}')\n",
    "            json.dump(stringKeys, fp)\n",
    "        df = pd.DataFrame.from_dict(similarityData.items(), orient=\"columns\")\n",
    "        df.columns = ['token', 'similarity']\n",
    "        print(df)\n",
    "        df.to_csv(f'csv-output/{filename}.tsv', sep='\\t', index=False, encoding='utf-8')\n",
    "\n",
    "        xml = dicttoxml(similarityData)\n",
    "        dom = parseString(xml)\n",
    "        print(dom.toprettyxml())\n",
    "        with open(f'xml-output/{filename}.xml', 'w') as xmlFile:\n",
    "            xml_decode = xml.decode()\n",
    "            xmlFile.write(xml_decode)\n",
    "            xmlFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0a63e4-e9ab-4bf2-bdbc-639454eaa6c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
